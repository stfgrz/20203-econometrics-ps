library(dlm)
library(TSstudio)
library(feasts)
library(tseries)
# Necessary packages for quantmod
library(zoo)
library(xts)
library(quantmod)
# ARDL
library(ARDL)
#Specifically for this assignment
library(glmnet)
# Datasets
library(readr)
library(fpp3)
# For fancy plots
library(ggthemes)
# Necessary packages for viridis
library(viridisLite)
library(viridis)
library(gridExtra)
library(magrittr)
library(textab)
# Packages related to tidyverse, for data manipulation
library(tidyverse) # includes (lubridate), (dplyr), (ggplot2), (tidyr), (tidyselect)
library(tinytex)
# To handle time changes
library(timechange)
# To solve conflicts
library(conflicted)
conflicts_prefer(dplyr::filter)
conflicts_prefer(dplyr::select)
# To solve conflicts
library(conflicted)
conflicts_prefer(dplyr::filter)
conflicts_prefer(dplyr::select)
#| label: Load the relevant libraries
# For descriptive analysis
library(skimr)
library(DataExplorer)
library(psych)
library(corrplot)
library(GGally)
library(patchwork)
library(scales)
# For model specification
library(lmtest)
library(sandwich)
library(forecast)
library(dynlm)
library(urca)
library(vars)
library(rugarch)
# Time series
library(dlm)
library(TSstudio)
library(feasts)
library(tseries)
# Necessary packages for quantmod
library(zoo)
library(xts)
library(quantmod)
# ARDL
library(ARDL)
#Specifically for this assignment
library(glmnet)
# Datasets
library(readr)
library(fpp3)
# For fancy plots
library(ggthemes)
# Necessary packages for viridis
library(viridisLite)
library(viridis)
library(gridExtra)
library(magrittr)
library(textab)
# Packages related to tidyverse, for data manipulation
library(tidyverse) # includes (lubridate), (dplyr), (ggplot2), (tidyr), (tidyselect)
library(tinytex)
# To handle time changes
library(timechange)
# To solve conflicts
library(conflicted)
conflicts_prefer(dplyr::filter)
conflicts_prefer(dplyr::select)
latvia <- readr::read_csv("~/Documents/GitHub/20203-econometrics-ps/ps2/data/20203-dataset-final.csv", col_types = cols())
dim(latvia)           # rows & cols
str(latvia)           # data types
skim(latvia)          # extended summary of each variable
gdp_vars       <- c("nGDP","rGDP","rGDP_pc","rGDP_USD","deflator")
cons_inv_vars  <- c("cons","rcons","cons_GDP","inv","inv_GDP","finv","finv_GDP")
bp_vars        <- c("exports","exports_GDP","imports","imports_GDP","CA","CA_GDP","USDfx","REER")
gov_vars       <- c("govexp","govexp_GDP","govrev","govrev_GDP",
"govtax","govtax_GDP","govdef","govdef_GDP","govdebt","govdebt_GDP")
bc_vars        <- c("HPI","CPI","infl","unemp")
mon_vars       <- c("strate","ltrate","cbrate","M0","M1","M2")
#| label: Missingness diagnostics
# Overall missing value counts
latvia %>%
summarise_all(~ sum(is.na(.))) %>%
pivot_longer(everything(), names_to="variable", values_to="n_missing") %>%
arrange(desc(n_missing))
# Visualize missingness
DataExplorer::plot_missing(latvia)
#| label: Numeric variables: summaries & distributions
# Identify numeric columns
num_vars <- latvia %>% dplyr::select(where(is.numeric)) %>% names()
# Descriptive statistics (mean, sd, skew, kurtosis, etc.)
psych::describe(latvia[num_vars])
# Histograms + density plots
DataExplorer::plot_histogram(latvia[num_vars])
DataExplorer::plot_density(latvia[num_vars])
# Boxplots for outlier detection
# -> produce one combined figure faceted by variable
latvia %>%
pivot_longer(all_of(num_vars), names_to="variable", values_to="value") %>%
ggplot(aes(x=variable, y=value)) +
geom_boxplot(outlier.colour="firebrick") +
theme_bw() +
coord_flip() +
labs(title="Boxplots of Numeric Variables")
#| label: A helper to build a faceted time‐series plot for any named vector
plot_time_facet <- function(df, vars, title, ncol = 2) {
df %>%
select(year, all_of(vars)) %>%
pivot_longer(-year, names_to = "variable", values_to = "value") %>%
ggplot(aes(x = year, y = value)) +
geom_line(color = "#1f78b4", linewidth = 1) +
facet_wrap(~ variable, scales = "free_y", ncol = ncol) +
labs(title = title,
x     = "Year",
y     = NULL) +
theme_minimal(base_size = 12) +
theme(
plot.title       = element_text(face = "bold", size = 14, hjust = 0.5),
strip.text       = element_text(face = "bold"),
panel.grid.minor = element_blank()
)
}
p_gdp      <- plot_time_facet(latvia, gdp_vars,      "GDP Measures")
p_cons_inv <- plot_time_facet(latvia, cons_inv_vars, "Consumption & Investment")
p_bp       <- plot_time_facet(latvia, bp_vars,       "Balance of Payments")
p_gov      <- plot_time_facet(latvia, gov_vars,      "Government Intervention")
p_bc       <- plot_time_facet(latvia, bc_vars,       "Business Cycle Indicators")
p_mon      <- plot_time_facet(latvia, mon_vars,      "Monetary Measures")
print(p_gdp)
print(p_cons_inv)
print(p_bp)
print(p_gov)
print(p_bc)
print(p_mon)
# assume latvia is your data.frame and already loaded
# build a “general‐to‐specific” starting model
model_lrm <- lm(infl ~ rGDP_pc + M2 + unemp + USDfx, data=latvia)
# summary & robust SEs
coeftest(model_lrm, vcov = vcovHC(model_lrm, type="HC1"))
bptest(model_lrm)        # test heteroskedasticity :contentReference[oaicite:2]{index=2}:contentReference[oaicite:3]{index=3}
dwtest(model_lrm)        # Durbin–Watson for serial correlation
# convert to ts
infl_ts <- ts(latvia$infl, start=2001, frequency=1)
# automatic ARIMA selection (here d=0 since we model year-on-year rate)
auto_fit <- auto.arima(infl_ts, max.p=4, max.q=0, seasonal=TRUE) # There is room to play around with command specifications
summary(auto_fit)
checkresiduals(auto_fit)
# form time series ts object for all vars
lat_ts <- ts(dplyr::select(latvia, infl, rGDP_pc, M2, unemp, cbrate), start=2001, frequency=1)
# ARDL(1,1) example: infl_t ~ infl_{t-1} + ΔM2_t + M2_{t-1}
model_ardl <- dynlm(infl ~ L(infl,1) + diff(M2) + L(M2,1), data=lat_ts)
summary(model_ardl)
# 1) test for cointegration between levels of infl and M2
coint_test <- ca.jo(ts.union(infl_ts, ts(latvia$M2, start=2001)), type="trace", K=2)
summary(coint_test)
# 2) if cointegrated, extract the long-run residual
beta_hat <- coint_test@V[,1]       # normalized cointegration vector
ec_term   <- ts(cbind(infl_ts, ts(latvia$M2,2001))[ ,1:2] %*% beta_hat, start=2001)
# 3) ECM: Δinfl ~ ΔM2 + lag(ec_term)
ecm <- dynlm(d(infl) ~ d(M2) + L(ec_term,1), data=lat_ts)
summary(ecm)
# select variables
var_data <- ts(
latvia[, c("infl", "rGDP_pc", "M2")],
start     = 2001,
frequency = 1
)
# Now select lags and fit:
lag_sel   <- VARselect(var_data, lag.max = 4, type = "const")
p         <- lag_sel$selection["AIC(n)"]
var_model <- vars::VAR(var_data, p = p, type = "const")
summary(var_model)
# impulse responses
irf(var_model, impulse="M2", response="infl", n.ahead=8) %>% plot()
install.packages("broom")
install.packages("broom")
#| label: Load the relevant libraries
# For descriptive analysis
library(skimr)
library(DataExplorer)
library(psych)
library(corrplot)
library(GGally)
library(patchwork)
library(scales)
# For model specification
library(lmtest)
library(sandwich)
library(forecast)
library(dynlm)
library(urca)
library(vars)
library(rugarch)
# Time series
library(dlm)
library(TSstudio)
library(feasts)
library(tseries)
# Necessary packages for quantmod
library(zoo)
library(xts)
library(quantmod)
# ARDL
library(ARDL)
# Datasets
library(readr)
library(fpp3)
# For fancy plots
library(ggthemes)
# Necessary packages for viridis
library(viridisLite)
library(viridis)
library(gridExtra)
library(magrittr)
library(textab)
library(broom)
# Packages related to tidyverse, for data manipulation
library(tidyverse) # includes (lubridate), (dplyr), (ggplot2), (tidyr), (tidyselect)
library(tinytex)
# To handle time changes
library(timechange)
#| label: Load the relevant libraries
# For descriptive analysis
library(skimr)
library(DataExplorer)
library(psych)
library(corrplot)
library(GGally)
library(patchwork)
library(scales)
# For model specification
library(lmtest)
library(sandwich)
library(forecast)
library(dynlm)
library(urca)
library(vars)
library(rugarch)
# Time series
library(dlm)
library(TSstudio)
library(feasts)
library(tseries)
# Necessary packages for quantmod
library(zoo)
library(xts)
library(quantmod)
# ARDL
library(ARDL)
# Datasets
library(readr)
library(fpp3)
# For fancy plots
library(ggthemes)
# Necessary packages for viridis
library(viridisLite)
library(viridis)
library(gridExtra)
library(magrittr)
library(textab)
library(broom)
# Packages related to tidyverse, for data manipulation
library(tidyverse) # includes (lubridate), (dplyr), (ggplot2), (tidyr), (tidyselect)
library(tinytex)
# To handle time changes
library(timechange)
# To solve conflicts
library(conflicted)
conflicts_prefer(dplyr::filter)
conflicts_prefer(dplyr::select)
lrm_aic   <- AIC(model_lrm)
lrm_bic   <- BIC(model_lrm)
lrm_rmse  <- sqrt(mean(resid(model_lrm)^2))
lrm_dw    <- dwtest(model_lrm)$statistic
lrm_bp_p  <- bptest(model_lrm)$p.value
arima_aic  <- AIC(auto_fit)
arima_bic  <- BIC(auto_fit)
arima_acc  <- accuracy(auto_fit)    # training‐set ME, RMSE, MAE…
arima_rmse <- arima_acc["Training set", "RMSE"]
arima_lb   <- Box.test(residuals(auto_fit), lag=5, type="Ljung")$p.value
ardl_aic   <- AIC(model_ardl)
ardl_bic   <- BIC(model_ardl)
ardl_rmse  <- sqrt(mean(resid(model_ardl)^2))
ecm_aic    <- AIC(ecm)
ecm_bic    <- BIC(ecm)
ecm_rmse   <- sqrt(mean(resid(ecm)^2))
var_aic    <- AIC(var_model)
var_bic    <- BIC(var_model)
# extract inflation equation residuals
infl_resid <- residuals(var_model)$infl
var_aic    <- AIC(var_model)
var_bic    <- BIC(var_model)
# extract inflation equation residuals
infl_resid <- residuals(var_model)[, "infl"]
var_rmse   <- sqrt(mean(infl_resid^2))
# stability: largest root must be < 1
stabs     <- max(Mod(polyroot(c(1, -VARselect(var_data,4)$selection["AIC(n)"]))))
results <- tibble::tibble(
Model   = c("OLS-LRM","ARIMA(1,0,0)","ARDL(1,1)","ECM","VAR(4)"),
AIC     = c(lrm_aic, arima_aic, ardl_aic, ecm_aic, var_aic),
BIC     = c(lrm_bic, arima_bic, ardl_bic, ecm_bic, var_bic),
RMSE    = c(lrm_rmse, arima_rmse, ardl_rmse, ecm_rmse, var_rmse),
`No AC?` = c(lrm_dw>1.75, arima_lb>0.05, NA, NA, NA),
Notes   = c(
ifelse(lrm_bp_p>0.05,"H-V OK","H-V heterosked") %>% paste0("; DW=", round(lrm_dw,2)),
ifelse(arima_lb>0.05,"no autocorr.","autocorr."),
paste0("R²=", round(summary(model_ardl)$r.squared,2)),
paste0("EC term p=", round(coef(summary(ecm))["L(ec_term, 1)","Pr(>|t|)"],3)),
paste0("max root=", round(stabs,3))
)
)
print(results)
#| label: Load the relevant libraries
# For descriptive analysis
library(skimr)
library(DataExplorer)
library(psych)
library(corrplot)
library(GGally)
library(patchwork)
library(scales)
# For model specification
library(lmtest)
library(sandwich)
library(forecast)
library(dynlm)
library(urca)
library(vars)
library(rugarch)
# For diagnostics
library(strucchange)
# Time series
library(dlm)
library(TSstudio)
library(feasts)
library(tseries)
# Necessary packages for quantmod
library(zoo)
library(xts)
library(quantmod)
# ARDL
library(ARDL)
# Datasets
library(readr)
library(fpp3)
# For fancy plots
library(ggthemes)
# Necessary packages for viridis
library(viridisLite)
library(viridis)
library(gridExtra)
library(magrittr)
library(textab)
library(broom)
# Packages related to tidyverse, for data manipulation
library(tidyverse) # includes (lubridate), (dplyr), (ggplot2), (tidyr), (tidyselect)
library(tinytex)
# To handle time changes
library(timechange)
# specify formula and data
form <- infl ~ rGDP_pc + M2 + unemp + USDfx
# Estimate breakpoints (allowing up to 5 candidate breaks; here we’ll pick 1)
#    h = minimal segment size (here 0.15*T ≈ 3 obs per regime)
bp <- breakpoints(form, data = latvia, h = 0.15)
# specify formula and data
form <- infl ~ rGDP_pc + M2 + unemp + USDfx
latvia_small <- latvia %>%
select(year, rGDP_pc, M2, unemp, USDfx)
# Estimate breakpoints (allowing up to 5 candidate breaks; here we’ll pick 1)
#    h = minimal segment size (here 0.15*T ≈ 3 obs per regime)
bp <- breakpoints(form, data = latvia_small, h = 0.15)
# specify formula and data
form <- infl ~ rGDP_pc + M2 + unemp + USDfx
latvia_small <- latvia %>%
select(year, infl, rGDP_pc, M2, unemp, USDfx)
# Estimate breakpoints (allowing up to 5 candidate breaks; here we’ll pick 1)
#    h = minimal segment size (here 0.15*T ≈ 3 obs per regime)
bp <- breakpoints(form, data = latvia_small, h = 0.15)
# specify formula and data
form <- infl ~ rGDP_pc + M2 + unemp + USDfx
latvia_small <- latvia %>%
select(year, infl, rGDP_pc, M2, unemp, USDfx)
# Estimate breakpoints (allowing up to 5 candidate breaks; here we’ll pick 1)
#    h = minimal segment size (here 0.15*T ≈ 3 obs per regime)
bp <- breakpoints(form, data = latvia_small, h = 0.25)
# Inspect the BIC‐optimal number of breaks
#    (summary(bp) will show you RSS, BIC for m = 0,1,2,…)
summary(bp)
# Extract the single best break (m = 1)
bp1 <- breakpoints(bp, breaks = 1)
bp1
# Translate that into a calendar year
#    `bp1$breakpoints` gives the OBS row number of the break:
obs_break <- bp1$breakpoints[1]
year_break <- latvia_small$year[obs_break]
cat("Estimated break year:", year_break, "\n")
# Plot the supF statistic over time
plot(bp, breaks=1)
lines(bp1)
# Now you can plug `year_break` into your CH1–CH4 code:
break_year <- year_break
lat1 <- filter(latvia, year <= break_year)
lat2 <- filter(latvia, year >  break_year)
T1   <- nrow(lat1);  T2 <- nrow(lat2)
#–– 1) Fit full‐sample and subsample OLS ––#
mod_full <- lm(formula, data=latvia)
lat1 <- filter(latvia_small, year <= break_year)
lat2 <- filter(latvia_small, year >  break_year)
T1   <- nrow(lat1);  T2 <- nrow(lat2)
#–– 1) Fit full‐sample and subsample OLS ––#
mod_full <- lm(formula, data=latvia_small)
lat1 <- filter(latvia_small, year <= break_year)
lat2 <- filter(latvia_small, year >  break_year)
T1   <- nrow(lat1);  T2 <- nrow(lat2)
#–– 1) Fit full‐sample and subsample OLS ––#
mod_full <- lm(form, data=latvia_small)
RSS_full <- sum(resid(mod_full)^2)
mod1 <- lm(formula, data=lat1)
lat1 <- filter(latvia_small, year <= break_year)
lat2 <- filter(latvia_small, year >  break_year)
T1   <- nrow(lat1);  T2 <- nrow(lat2)
#–– 1) Fit full‐sample and subsample OLS ––#
mod_full <- lm(form, data=latvia_small)
RSS_full <- sum(resid(mod_full)^2)
mod1 <- lm(form, data=lat1)
RSS1 <- sum(resid(mod1)^2)
# need special handling if T2 > k:
if(T2 > k) {
mod2 <- lm(formula, data=lat2)
RSS2 <- sum(resid(mod2)^2)
# CH1: breakpoint test for β1=β2  :contentReference[oaicite:1]{index=1}:contentReference[oaicite:2]{index=2}
CH1_stat <- ((RSS_full - RSS1 - RSS2)/k) / ((RSS1 + RSS2)/(T - 2*k))
CH1_p    <- 1 - pf(CH1_stat, df1 = k, df2 = T - 2*k)
# CH2: variance–stability σ1²=σ2²  :contentReference[oaicite:3]{index=3}:contentReference[oaicite:4]{index=4}
CH2_stat <- (RSS2/(T2 - k)) / (RSS1/(T1 - k))
CH2_p    <- 1 - pf(CH2_stat, df1 = T2 - k, df2 = T1 - k)
}
lat1 <- filter(latvia_small, year <= break_year)
lat2 <- filter(latvia_small, year >  break_year)
T1   <- nrow(lat1);  T2 <- nrow(lat2)
#–– 1) Fit full‐sample and subsample OLS ––#
mod_full <- lm(form, data=latvia_small)
RSS_full <- sum(resid(mod_full)^2)
mod1 <- lm(form, data=lat1)
RSS1 <- sum(resid(mod1)^2)
# need special handling if T2 > k:
if(T2 > k) {
mod2 <- lm(form, data=lat2)
RSS2 <- sum(resid(mod2)^2)
# CH1: breakpoint test for β1=β2  :contentReference[oaicite:1]{index=1}:contentReference[oaicite:2]{index=2}
CH1_stat <- ((RSS_full - RSS1 - RSS2)/k) / ((RSS1 + RSS2)/(T - 2*k))
CH1_p    <- 1 - pf(CH1_stat, df1 = k, df2 = T - 2*k)
# CH2: variance–stability σ1²=σ2²  :contentReference[oaicite:3]{index=3}:contentReference[oaicite:4]{index=4}
CH2_stat <- (RSS2/(T2 - k)) / (RSS1/(T1 - k))
CH2_p    <- 1 - pf(CH2_stat, df1 = T2 - k, df2 = T1 - k)
}
lat1 <- filter(latvia_small, year <= break_year)
lat2 <- filter(latvia_small, year >  break_year)
T1   <- nrow(lat1);  T2 <- nrow(lat2)
#–– 1) Fit full‐sample and subsample OLS ––#
mod_full <- lm(form, data=latvia_small)
RSS_full <- sum(resid(mod_full)^2)
mod1 <- lm(form, data=lat1)
RSS1 <- sum(resid(mod1)^2)
# set the number of parameters (look at `form` in the chunk above)
k <- 4
# need special handling if T2 > k:
if(T2 > k) {
mod2 <- lm(form, data=lat2)
RSS2 <- sum(resid(mod2)^2)
# CH1: breakpoint test for β1=β2  :contentReference[oaicite:1]{index=1}:contentReference[oaicite:2]{index=2}
CH1_stat <- ((RSS_full - RSS1 - RSS2)/k) / ((RSS1 + RSS2)/(T - 2*k))
CH1_p    <- 1 - pf(CH1_stat, df1 = k, df2 = T - 2*k)
# CH2: variance–stability σ1²=σ2²  :contentReference[oaicite:3]{index=3}:contentReference[oaicite:4]{index=4}
CH2_stat <- (RSS2/(T2 - k)) / (RSS1/(T1 - k))
CH2_p    <- 1 - pf(CH2_stat, df1 = T2 - k, df2 = T1 - k)
}
# CH3 & CH4: “forecast”‐style tests if T2 may be small (or always doable) :contentReference[oaicite:5]{index=5}:contentReference[oaicite:6]{index=6}
# CH3: parameter‐stability via predictive errors
e2 <- lat2$infl - predict(mod1, newdata = lat2)
CH3_stat <- ((RSS_full - RSS1)/RSS1) * ((T1 - k)/T2)
CH3_p    <- 1 - pf(CH3_stat, df1 = T2, df2 = T1 - k)
# CH4: variance‐instability via χ² of forecast errors
sigma1_hat <- RSS1/(T1 - k)
CH4_stat    <- sum(e2^2) / sigma1_hat
CH4_p       <- 1 - pchisq(CH4_stat, df = T2)
#–– 2) Display results ––#
tests <- tibble(
Test      = c("CH1 (β-break)", "CH2 (σ² stability)",
"CH3 (forecast β‐stability)", "CH4 (forecast σ²)"),
Statistic = c(CH1_stat, CH2_stat, CH3_stat, CH4_stat),
`p‐value` = c(CH1_p,    CH2_p,    CH3_p,    CH4_p)
)
print(tests)
